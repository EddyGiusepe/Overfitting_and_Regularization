{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularization_L2_weight_decay.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2hEITR8Co6327aeeisMJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyGiusepe/Overfitting_and_Regularization/blob/main/Regularization_L2_weight_decay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align=\"center\">Weight decay in Neural Network with Pytorch (L2 Regularization)</h2>\n",
        "\n"
      ],
      "metadata": {
        "id": "Uuiuizbe-liP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Scientist: Dr.Eddy Giusepe Chirinos Isidro"
      ],
      "metadata": {
        "id": "RIHUfIZd-8c9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O decaimento de peso (`weight decay`) é uma técnica de regularização que adiciona uma pequena penalidade, geralmente a `Norma L2` dos pesos (todos os pesos do modelo), à função de perda."
      ],
      "metadata": {
        "id": "yZiHihBE_jPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.oreilly.com/library/view/hands-on-machine-learning/9781788393485/assets/320843d0-3683-4422-80b2-c2913f8d02d4.png)"
      ],
      "metadata": {
        "id": "7197NCASATyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como usamos weight decay?"
      ],
      "metadata": {
        "id": "Z03rGYVZBZA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para usar o `decaimento de peso`, podemos simplesmente definir o parâmetro de decaimento de peso no otimizador `torch.optim.SGD` ou no otimizador `torch.optim.Adam`. Aqui usamos $1e-4$ como padrão para `weight_decay`.\n",
        "\n",
        "\n",
        "Assim:"
      ],
      "metadata": {
        "id": "BxJwanNKBhmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "optimizer = torch.optim.SGD(my_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(my_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "```"
      ],
      "metadata": {
        "id": "fUpMEZIiNN6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Por que usamos a weight decay?\n",
        "\n",
        "* Para evitar o sobreajuste (`Overfitting`)\n",
        "\n",
        "* Para manter os pesos pequenos e evitar a explosão do gradiente (`Exploding Gradient`).\n",
        "\n"
      ],
      "metadata": {
        "id": "kpVLSDKsCdNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CRxShXR3-HHJ"
      },
      "outputs": [],
      "source": [
        "# Importamos as nossas bibliotecas \n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtendo os nomes dos parâmetros"
      ],
      "metadata": {
        "id": "lSKP3mFZFFnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nosso Modelo\n",
        "\n",
        "#my_model = models.resnet50(pretrained=False) #  Deprecate\n",
        "my_model = models.resnet50()"
      ],
      "metadata": {
        "id": "jXJV1YHCD3C1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, parameter in my_model.named_parameters():\n",
        "  print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzRZl5oMFBc6",
        "outputId": "ba2c5da2-07de-4568-e709-5ed4281b7082"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight\n",
            "bn1.weight\n",
            "bn1.bias\n",
            "layer1.0.conv1.weight\n",
            "layer1.0.bn1.weight\n",
            "layer1.0.bn1.bias\n",
            "layer1.0.conv2.weight\n",
            "layer1.0.bn2.weight\n",
            "layer1.0.bn2.bias\n",
            "layer1.0.conv3.weight\n",
            "layer1.0.bn3.weight\n",
            "layer1.0.bn3.bias\n",
            "layer1.0.downsample.0.weight\n",
            "layer1.0.downsample.1.weight\n",
            "layer1.0.downsample.1.bias\n",
            "layer1.1.conv1.weight\n",
            "layer1.1.bn1.weight\n",
            "layer1.1.bn1.bias\n",
            "layer1.1.conv2.weight\n",
            "layer1.1.bn2.weight\n",
            "layer1.1.bn2.bias\n",
            "layer1.1.conv3.weight\n",
            "layer1.1.bn3.weight\n",
            "layer1.1.bn3.bias\n",
            "layer1.2.conv1.weight\n",
            "layer1.2.bn1.weight\n",
            "layer1.2.bn1.bias\n",
            "layer1.2.conv2.weight\n",
            "layer1.2.bn2.weight\n",
            "layer1.2.bn2.bias\n",
            "layer1.2.conv3.weight\n",
            "layer1.2.bn3.weight\n",
            "layer1.2.bn3.bias\n",
            "layer2.0.conv1.weight\n",
            "layer2.0.bn1.weight\n",
            "layer2.0.bn1.bias\n",
            "layer2.0.conv2.weight\n",
            "layer2.0.bn2.weight\n",
            "layer2.0.bn2.bias\n",
            "layer2.0.conv3.weight\n",
            "layer2.0.bn3.weight\n",
            "layer2.0.bn3.bias\n",
            "layer2.0.downsample.0.weight\n",
            "layer2.0.downsample.1.weight\n",
            "layer2.0.downsample.1.bias\n",
            "layer2.1.conv1.weight\n",
            "layer2.1.bn1.weight\n",
            "layer2.1.bn1.bias\n",
            "layer2.1.conv2.weight\n",
            "layer2.1.bn2.weight\n",
            "layer2.1.bn2.bias\n",
            "layer2.1.conv3.weight\n",
            "layer2.1.bn3.weight\n",
            "layer2.1.bn3.bias\n",
            "layer2.2.conv1.weight\n",
            "layer2.2.bn1.weight\n",
            "layer2.2.bn1.bias\n",
            "layer2.2.conv2.weight\n",
            "layer2.2.bn2.weight\n",
            "layer2.2.bn2.bias\n",
            "layer2.2.conv3.weight\n",
            "layer2.2.bn3.weight\n",
            "layer2.2.bn3.bias\n",
            "layer2.3.conv1.weight\n",
            "layer2.3.bn1.weight\n",
            "layer2.3.bn1.bias\n",
            "layer2.3.conv2.weight\n",
            "layer2.3.bn2.weight\n",
            "layer2.3.bn2.bias\n",
            "layer2.3.conv3.weight\n",
            "layer2.3.bn3.weight\n",
            "layer2.3.bn3.bias\n",
            "layer3.0.conv1.weight\n",
            "layer3.0.bn1.weight\n",
            "layer3.0.bn1.bias\n",
            "layer3.0.conv2.weight\n",
            "layer3.0.bn2.weight\n",
            "layer3.0.bn2.bias\n",
            "layer3.0.conv3.weight\n",
            "layer3.0.bn3.weight\n",
            "layer3.0.bn3.bias\n",
            "layer3.0.downsample.0.weight\n",
            "layer3.0.downsample.1.weight\n",
            "layer3.0.downsample.1.bias\n",
            "layer3.1.conv1.weight\n",
            "layer3.1.bn1.weight\n",
            "layer3.1.bn1.bias\n",
            "layer3.1.conv2.weight\n",
            "layer3.1.bn2.weight\n",
            "layer3.1.bn2.bias\n",
            "layer3.1.conv3.weight\n",
            "layer3.1.bn3.weight\n",
            "layer3.1.bn3.bias\n",
            "layer3.2.conv1.weight\n",
            "layer3.2.bn1.weight\n",
            "layer3.2.bn1.bias\n",
            "layer3.2.conv2.weight\n",
            "layer3.2.bn2.weight\n",
            "layer3.2.bn2.bias\n",
            "layer3.2.conv3.weight\n",
            "layer3.2.bn3.weight\n",
            "layer3.2.bn3.bias\n",
            "layer3.3.conv1.weight\n",
            "layer3.3.bn1.weight\n",
            "layer3.3.bn1.bias\n",
            "layer3.3.conv2.weight\n",
            "layer3.3.bn2.weight\n",
            "layer3.3.bn2.bias\n",
            "layer3.3.conv3.weight\n",
            "layer3.3.bn3.weight\n",
            "layer3.3.bn3.bias\n",
            "layer3.4.conv1.weight\n",
            "layer3.4.bn1.weight\n",
            "layer3.4.bn1.bias\n",
            "layer3.4.conv2.weight\n",
            "layer3.4.bn2.weight\n",
            "layer3.4.bn2.bias\n",
            "layer3.4.conv3.weight\n",
            "layer3.4.bn3.weight\n",
            "layer3.4.bn3.bias\n",
            "layer3.5.conv1.weight\n",
            "layer3.5.bn1.weight\n",
            "layer3.5.bn1.bias\n",
            "layer3.5.conv2.weight\n",
            "layer3.5.bn2.weight\n",
            "layer3.5.bn2.bias\n",
            "layer3.5.conv3.weight\n",
            "layer3.5.bn3.weight\n",
            "layer3.5.bn3.bias\n",
            "layer4.0.conv1.weight\n",
            "layer4.0.bn1.weight\n",
            "layer4.0.bn1.bias\n",
            "layer4.0.conv2.weight\n",
            "layer4.0.bn2.weight\n",
            "layer4.0.bn2.bias\n",
            "layer4.0.conv3.weight\n",
            "layer4.0.bn3.weight\n",
            "layer4.0.bn3.bias\n",
            "layer4.0.downsample.0.weight\n",
            "layer4.0.downsample.1.weight\n",
            "layer4.0.downsample.1.bias\n",
            "layer4.1.conv1.weight\n",
            "layer4.1.bn1.weight\n",
            "layer4.1.bn1.bias\n",
            "layer4.1.conv2.weight\n",
            "layer4.1.bn2.weight\n",
            "layer4.1.bn2.bias\n",
            "layer4.1.conv3.weight\n",
            "layer4.1.bn3.weight\n",
            "layer4.1.bn3.bias\n",
            "layer4.2.conv1.weight\n",
            "layer4.2.bn1.weight\n",
            "layer4.2.bn1.bias\n",
            "layer4.2.conv2.weight\n",
            "layer4.2.bn2.weight\n",
            "layer4.2.bn2.bias\n",
            "layer4.2.conv3.weight\n",
            "layer4.2.bn3.weight\n",
            "layer4.2.bn3.bias\n",
            "fc.weight\n",
            "fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desative `weight decay` em algumas camadas ou defina valores diferentes para diferentes camadas"
      ],
      "metadata": {
        "id": "aTy2v43oJSS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_weight_decay(net, l2_value, skip_list=()):\n",
        "  decay, no_decay = [], []\n",
        "\n",
        "  for name, param in net.named_parameters():\n",
        "    if not param.requires_grad: continue # Congelamento dos pesos\n",
        "  if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
        "    no_decay.append(param)\n",
        "  else: decay.append(param)\n",
        "\n",
        "  return [{'params': no_decay, 'weight_decay': 0}, {'params': decay, 'weight_decay': l2_value}]\n",
        "\n",
        "\n",
        "\n",
        "# E a lista retornada é passada para o otimizador:  \n",
        "params = custom_weight_decay(my_model, 2e-5)\n",
        "\n",
        "sgd = torch.optim.SGD(params, lr=0.05)\n"
      ],
      "metadata": {
        "id": "qASb3T65GRfn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificando se os pesos são menores quando aplico weight_decay"
      ],
      "metadata": {
        "id": "4S_o0pnlKPF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "np.set_printoptions(8, suppress=True)\n",
        "\n",
        "x_np = np.random.random((3, 4)).astype(np.double)\n",
        "weights_np = np.random.random((4, 5)).astype(np.double)\n",
        "\n",
        "x_torch = torch.tensor(x_np, requires_grad=True)\n",
        "weights_torch = torch.tensor(weights_np, requires_grad=True)\n",
        "\n",
        "print('Pesos originais', weights_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoMLcSjHGRcp",
        "outputId": "22af045d-c70d-463e-818b-7ef10b167c09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos originais tensor([[0.4386, 0.0597, 0.3980, 0.7380, 0.1825],\n",
            "        [0.1755, 0.5316, 0.5318, 0.6344, 0.8494],\n",
            "        [0.7245, 0.6110, 0.7224, 0.3230, 0.3618],\n",
            "        [0.2283, 0.2937, 0.6310, 0.0921, 0.4337]], dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################ 0 weight decay  ##################\n",
        "\n",
        "\n",
        "lr = 0.1\n",
        "sgd = torch.optim.SGD([weights_torch], lr=lr, weight_decay=0)\n",
        "\n",
        "y_torch = torch.matmul(x_torch, weights_torch)\n",
        "loss = y_torch.sum()\n",
        "\n",
        "sgd.zero_grad()\n",
        "loss.backward()\n",
        "sgd.step()\n",
        "\n",
        "w_grad = weights_torch.grad.data.numpy()\n",
        "print('weight decay igual a 0', weights_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Erb6i9GRaH",
        "outputId": "a0eec7d2-ed4b-42a6-a3e4-6c3d68f4cdec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight decay igual a 0 tensor([[ 0.2489, -0.1300,  0.2084,  0.5483, -0.0072],\n",
            "        [ 0.0653,  0.4214,  0.4217,  0.5243,  0.7393],\n",
            "        [ 0.5694,  0.4559,  0.5674,  0.1679,  0.2067],\n",
            "        [ 0.0317,  0.0972,  0.4345, -0.1044,  0.2372]], dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################ NOW 1 weight decay ######################\n",
        "\n",
        "weights_torch = torch.tensor(weights_np, requires_grad=True)\n",
        "\n",
        "print('Reinicializar pesos originais (Reset Original weights)', weights_torch)\n",
        "\n",
        "sgd = torch.optim.SGD([weights_torch], lr=lr, weight_decay=1)\n",
        "\n",
        "y_torch = torch.matmul(x_torch, weights_torch)\n",
        "loss = y_torch.sum()\n",
        "\n",
        "sgd.zero_grad()\n",
        "loss.backward()\n",
        "sgd.step()\n",
        "\n",
        "w_grad = weights_torch.grad.data.numpy()\n",
        "print('weight decay igual a 1', weights_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC5r4cv_GRXm",
        "outputId": "08ceeafa-5d01-418b-e469-f724b885e0e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinicializar pesos originais (Reset Original weights) tensor([[0.4386, 0.0597, 0.3980, 0.7380, 0.1825],\n",
            "        [0.1755, 0.5316, 0.5318, 0.6344, 0.8494],\n",
            "        [0.7245, 0.6110, 0.7224, 0.3230, 0.3618],\n",
            "        [0.2283, 0.2937, 0.6310, 0.0921, 0.4337]], dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "weight decay igual a 1 tensor([[ 0.2050, -0.1360,  0.1686,  0.4745, -0.0254],\n",
            "        [ 0.0478,  0.3683,  0.3685,  0.4608,  0.6544],\n",
            "        [ 0.4969,  0.3948,  0.4951,  0.1356,  0.1705],\n",
            "        [ 0.0089,  0.0678,  0.3714, -0.1136,  0.1938]], dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}